# ComposeForChucK
Compose is a Framework to create music for the programming language ChucK

## Important Note
This framework is still a work in progress, it was started as a weekend project that need hours of work. If anyone is interested
in collaborating or helping develop this framework, it would be ausome. 

## Introduction
Compose is a Framework that offers highlevel operations to write music with Chuck. From playing certain notes, to working with 
scales and modes y creating arteficial improvisation.

Please feel free to modify and use Compose in your musical projects. This first prototype of the framework allowes the user to
any note, to choose scales and play scales. It offers a starting point to work on a base of musical theory. All the notes have 
been program, the most common scales and modes have been programed. The idea is to use this framework the create theoretical 
complex music with Chuck

## Instalation
If you do not have installed chuck, the following link has everything you need: http://chuck.cs.princeton.edu/

To install the Compose framework: <br/>
    - Open miniAudicle <br/>
    - Start the virtual machine <br/>
    - Run Compose code <br/>
    - Now you have your framework up and running, you can write your program in another tab and work with the Compose Framework<br/>
    Note: everytime you run a program that uses Compose, you will need to run the Compose code first

## Future
Compose started as a weekend project with the idea to create a intelligent program that created music by itself. That the user
would input a certain feeling and the program would create a musical piece that would interpret this feeling. This at first could
a description of a human feeling like sad, happy, excited, etc. Or another idea could be to translate a color that the user feels
describes his mood. 

The final masterpiece of this program would be a program where the users puts on a neuro head set and the program creates a 
musical piece that interprets the user in real time. The neuro head set could pick up various inputs that could be transalted
into a combination of notes and melodies. Another important input could be the users pulse rate. The beats per minute of the 
musical beat could be sincronized in real time with the users pulse rate. This could vary drastically a mood of the musical 
piece. 

The Mona Lisa:<br/>
Imagine a program like the one described as the final masterpiece. Now image using this program as an artistic expierience.
Now imagine taking it to the next level, and putting on an Oculus Rift that gives you amazing visuals that interpret the music
that is playing. An Artistic Expierience that represents yourself. It would be like looking in the mirror of your innerself.

Today is a gift, thats why we call it present:<br/>
LetÂ´s interpret the present moment. Another, taking it to the next level idea... Imagine a system that could interpret the present
moment. The system installed in a box with sensors and speakers. And wherever you take this magic box, it played a never ending
song that interprets its souroundings in real time. If its raining, cold, worm, windy, sun, moon, darkness, whatever the system
interprets from the current moment in time and space. Created into music. wow...


##Methods
I diveded Compose into three sub groups, depending on how high or low level the logic of the methods. 
####Working with notes
TODO

####Working with scales and modes
TODO

####Arteficial Improvisation
TODO

##Example:
TODO
